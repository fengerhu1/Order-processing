<!DOCTYPE html>
<html>
<head>
<title>DTSS-doc.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: "Segoe WPC", "Segoe UI", "SFUIText-Light", "HelveticaNeue-Light", sans-serif, "Droid Sans Fallback";
	font-size: 14px;
	padding: 0 12px;
	line-height: 22px;
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}


body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	color: #4080D0;
	text-decoration: none;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

h1 code,
h2 code,
h3 code,
h4 code,
h5 code,
h6 code {
	font-size: inherit;
	line-height: auto;
}

a:hover {
	color: #4080D0;
	text-decoration: underline;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left: 5px solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 14px;
	line-height: 19px;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

.mac code {
	font-size: 12px;
	line-height: 18px;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

/** Theming */

.vscode-light,
.vscode-light pre code {
	color: rgb(30, 30, 30);
}

.vscode-dark,
.vscode-dark pre code {
	color: #DDD;
}

.vscode-high-contrast,
.vscode-high-contrast pre code {
	color: white;
}

.vscode-light code {
	color: #A31515;
}

.vscode-dark code {
	color: #D7BA7D;
}

.vscode-light pre:not(.hljs),
.vscode-light code > div {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre:not(.hljs),
.vscode-dark code > div {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre:not(.hljs),
.vscode-high-contrast code > div {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

.vscode-light blockquote,
.vscode-dark blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.vscode-high-contrast blockquote {
	background: transparent;
	border-color: #fff;
}
</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family:  "Meiryo", "Segoe WPC", "Segoe UI", "SFUIText-Light", "HelveticaNeue-Light", sans-serif, "Droid Sans Fallback";
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

</head>
<body>
<h4 id="1%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83%E6%A6%82%E8%BF%B0">1.系统环境概述</h4>
<p>我们的分布式事务处理系统（DTSS）部署在一个由多台虚拟主机组成的集群中，这个集群通过openstack平台统一创建与管理。</p>
<p>以下是该集群的具体配置:</p>
<p>- 节点数及名称: 4 （vm1 vm2 vm3 vm4）</p>
<p>- 节点实例资源：4vCPU + 8GB内存空间 + 80GB硬盘空间</p>
<p>- 四个节点之间可通过集群网络相互通信，节点VM1绑定了浮动ip，外部网络可通过端口30430-30439与VM1通信</p>
<p>分布式事务处理系统由多个组件组成:</p>
<p><strong>-</strong> <strong>Hadoop集群</strong></p>
<p>Hadoop集群搭建在四个节点上，vm1为namenode，vm2，vm3，vm4为datanode，为Spark集群提供分布式存储以及yarn调度的支持</p>
<p><strong>- Spark集群</strong></p>
<p>Spark集群搭建在四个节点上, vm1为spark-master, vm2, vm3, vm4为spark-worker，本系统使用Spark平台的Spark Streaming组件完成订单数据流的处理及计算</p>
<p><strong>- Kafka消息队列</strong></p>
<p>Kafka集群搭建在vm2，vm3，vm4三个节点上，Kafka消息队列连接web API服务与Spark集群，缓冲订单消息</p>
<p><strong>- Zookeeper集群</strong></p>
<p>Zookeeper集群搭建在vm2，vm3，vm4三个节点上，为Kafka集群提供协调服务，为事务处理系统提供分布式锁服务及配置管理服务</p>
<p><strong>- Mysql集群</strong></p>
<p>​    Mysql集群搭建在四个节点上，vm1为管理节点，vm2，vm3，vm4为存储节点及SQL节点，为事务处理系统提供数据库存储服务</p>
<p><strong>- Order Receiver Web服务</strong></p>
<p>​    事务处理系统对用户开放Http接口，receiver服务运行在vm2，vm3，vm4节点上，vm1运行着Nginx作为网关及负载均衡器</p>
<h4 id="2%E3%80%81%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA">2、环境搭建</h4>
<h5 id="%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83">基础环境</h5>
<p>Hadoop，Spark这些平台的运行都需要一些基础环境，这里不再详述安装过程，基础环境如下：</p>
<ul>
<li>
<p>Java 1.8.0_212</p>
</li>
<li>
<p>Scala 2.11.0</p>
</li>
</ul>
<h5 id="%E8%8A%82%E7%82%B9%E9%97%B4ssh%E5%85%8D%E5%AF%86%E9%80%9A%E4%BF%A1">节点间SSH免密通信</h5>
<p>事务处理系统中的大部分组件都搭建在分布式集群上，这些集群启动时往往需要通过SSH进行数据传输，执行指令等操作，所以我们首先需要配置四个节点之间SSH的通信。</p>
<ul>
<li>
<p>编辑/etc/host文件使得我们不需要用ip来识别节点</p>
<pre class="hljs"><code><div>10.0.0.77   vm1
10.0.0.154  vm2
10.0.0.137  vm3
10.0.0.115  vm4
</div></code></pre>
</li>
<li>
<p>在每个节点上使用指令<code>ssh-keygen -t rsa</code>为每个节点生成密钥对，再将所有节点的公钥一起拷贝到每个节点的.ssh/authorized_keys文件中，这样就实现了四个节点之间SSH免密登录。</p>
</li>
</ul>
<h5 id="%E6%90%AD%E5%BB%BAhadoop%E9%9B%86%E7%BE%A4">搭建Hadoop集群</h5>
<ul>
<li>
<p>从官网下载hadoop-3.1.2.tar.gz安装包，解压至/usr/local/hadoop文件夹</p>
</li>
<li>
<p>编辑<code>hadoop-env.sh</code>，<code>yarn-env.sh</code>，<code>core-site.xml</code>，<code>hdfs-site.xml</code>，<code>maprd-site.xml</code>，<code>yarn-site.xml</code>等配置文件，配置文件内容不在此展示。</p>
</li>
<li>
<p>编写<code>slaves</code>文件，添加vm2，vm3，vm4作为datanode</p>
<pre class="hljs"><code><div>vm2
vm3
vm4
</div></code></pre>
</li>
<li>
<p>将配置好的hadoop文件夹通过scp分发给vm2，vm3，vm4</p>
</li>
<li>
<p>使用命令<code>bin/hadoop namenode -format</code>格式化namenode</p>
</li>
<li>
<p>使用命令<code>sbin/start-all.sh</code>启动hadoop集群，通过jps命令可以看到namenode,datanode正常启动</p>
<pre class="hljs"><code><div>master（vm1）
[centos@vm1 ~]$ jps
5714 SecondaryNameNode
5963 ResourceManager
5455 NameNode
</div></code></pre>
<pre class="hljs"><code><div>slaves（vm2，vm3，vm4）
[centos@vm2 ~]$ jps
5255 NodeManager
5131 DataNode
</div></code></pre>
</li>
</ul>
<h5 id="%E6%90%AD%E5%BB%BAspark%E9%9B%86%E7%BE%A4">搭建Spark集群</h5>
<ul>
<li>
<p>从官网上下载<code>spark-2.4.3-bin-hadoop2.7.tar.gz</code>安装包</p>
</li>
<li>
<p>在<code>conf/spark-env.sh</code>添加配置配置hadoop目录及Spark集群配置</p>
<pre class="hljs"><code><div>export SCALA_HOME=/usr/lcoal/scala-2.11.0
export JAVA_HOME=/usr/local/java
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
SPARK_MASTER_IP=vm1
SPARK_LOCAL_DIRS=/home/centos/spark-2.2.1-bin-hadoop2.7
</div></code></pre>
</li>
<li>
<p>类似Hadoop集群，填写slaves文件配置vm2，vm3，vm4为spark-worker节点</p>
</li>
<li>
<p>执行命令<code>sbin/start-all.sh</code>启动Spark集群，通过jps命令可以看到master,worker正常启动</p>
<pre class="hljs"><code><div>master（vm1）
[centos@vm1 ~]$ jps
5714 SecondaryNameNode
28259 Master
5963 ResourceManager
5455 NameNode
</div></code></pre>
<pre class="hljs"><code><div>slaves（vm2，vm3，vm4）
[centos@vm2 ~]$ jps
5255 NodeManager
5131 DataNode
19101 Worker
</div></code></pre>
</li>
<li>
<p>浏览器输入ip http://202.120.40.8:30431/可以看到三个Worker节点正常存活</p>
<p><img src="./ds-imgs/spark.png" alt=""></p>
</li>
</ul>
<h5 id="%E6%90%AD%E5%BB%BAkafkazookeeper%E9%9B%86%E7%BE%A4">搭建Kafka&amp;Zookeeper集群</h5>
<p>由于最新版本的Kafka内置了Zookeeper，所以我们将这两个组件的搭建过程放在一起。</p>
<ul>
<li>
<p>从官网下载<code>kafka_2.12-2.2.0.tgz</code>安装包，解压</p>
</li>
<li>
<p>创建<code>~/kafka-logs</code>和<code>~/data/zk</code>目录分别用来存储kafka log及zookeeper数据</p>
</li>
<li>
<p>修改<code>config/server.properties</code>配置kafka，修改内容如下：</p>
<pre class="hljs"><code><div>broker.id=1       #broker id
num.partitions=3      #分区数量，一般与broker数量保持一致
listeners=PLAINTEXT://localhost:9092     #修改为本机ip
zookeeper.connect=vm2:2181,vm3:2181,vm4:2181      #三台服务zookeeper连接地址
host.name={vm2/vm3/vm4}      #根据自己的ip设置
log.dirs=/home/centos/kafka-logs/       #logs目录
</div></code></pre>
</li>
<li>
<p>修改<code>config/zookeeper.properties</code>配置Zookeeper，修改内容如下：</p>
<pre class="hljs"><code><div>#数据目录
dataDir=/home/centos/data/zk  
#设置连接参数
tickTime=2000
initLimit=10
syncLimit=5
#broker Id的服务地址
server.0=vm2:2888:3888
server.1=vm3:2888:3888
server.2=vm4:2888:3888
</div></code></pre>
</li>
<li>
<p>在每个节点的Zookeeper目录下添加myid文件，依次填写broker.id</p>
</li>
<li>
<p>使用命令<code>bin/zookeeper-server-start.sh config/zookeeper.properties &amp;</code>启动每个节点的Zookeeper</p>
</li>
<li>
<p>使用命令<code>bin/kafka-server-start.sh config/server.properties &amp;</code>启动每个节点的Kafka，通过jps命令可以看到Kafka,Zookeeper（QuorumPeerMain）正常启动。</p>
<pre class="hljs"><code><div>[centos@vm2 ~]$ jps
4199 QuorumPeerMain
5255 NodeManager
4712 Kafka
5131 DataNode
19101 Worker
</div></code></pre>
</li>
<li>
<p>创建系统所需topic<code>~/kafka_2.12-2.2.0/bin/kafka-topics.sh -create --zookeeper vm2:2181,vm3:2181,vm4:2181 -replication-factor 3 --partitions 3 --topic dsgroup</code></p>
</li>
</ul>
<h5 id="%E6%90%AD%E5%BB%BAmysql-cluster">搭建Mysql Cluster</h5>
<p>首先在在官网下载<code>mysql-cluster-gpl-7.5.15-linux-glibc2.12-x86_64.tar.gz</code>解压至<code>/usr/local/mysql-cluster</code>文件夹。</p>
<p><em><strong>Management节点</strong></em></p>
<ul>
<li>
<p>执行命令<code>cp bin/ndb_mgm* /usr/local/bin</code>将管理节点程序拷贝到PATH目录下</p>
</li>
<li>
<p>执行命令<code>chmod +x ndb_mgm*</code> 添加可执行权限</p>
</li>
<li>
<p>创建<code>/var/lib/mysql-cluster/config.ini</code>配置文件，填写Mysql 集群配置,可以看到我们将vm2,vm3,vm4配置为data节点及SQL节点</p>
<pre class="hljs"><code><div>[ndbd default]
# Options affecting ndbd processes on all data nodes:
NoOfReplicas=2    # Number of replicas
DataMemory=200M    # How much memory to allocate for data storage
IndexMemory=30M   # How much memory to allocate for index storage
                  # For DataMemory and IndexMemory, we have used the
                  # default values. Since the &quot;world&quot; database takes up
                  # only about 500KB, this should be more than enough for
                  # this example NDB Cluster setup.
                  # NOTE: IndexMemory is deprecated in NDB 7.6 and later; in
                  # these versions, resources for all data and indexes are 
                  # allocated by DataMemory and any that are set for IndexMemory
                  # are added to the DataMemory resource pool
ServerPort=2202   # This the default value; however, you can use any
                  # port that is free for all the hosts in the cluster
                  # Note1: It is recommended that you do not specify the port
                  # number at all and simply allow the default value to be used
                  # instead
                  # Note2: The port was formerly specified using the PortNumber 
                  # TCP parameter; this parameter is no longer available in NDB
                  # Cluster 7.5.

[ndb_mgmd]
# Management process options:
HostName=10.0.0.77          # Hostname or IP address of MGM node
NodeId=1
DataDir=/var/lib/mysql-cluster  # Directory for MGM node log files

[ndbd]
# Options for data node &quot;A&quot;:
                                # (one [ndbd] section per data node)
HostName=10.0.0.154          # Hostname or IP address
NodeId=2                        # Node ID for this data node
DataDir=/usr/local/mysql/data   # Directory for this data node's data files

[ndbd]
# Options for data node &quot;B&quot;:
HostName=10.0.0.137          # Hostname or IP address
NodeId=3                        # Node ID for this data node
DataDir=/usr/local/mysql/data   # Directory for this data node's data files

[ndbd]
# Options for data node &quot;B&quot;:
HostName=10.0.0.115          # Hostname or IP address
NodeId=4                        # Node ID for this data node
DataDir=/usr/local/mysql/data   # Directory for this data node's data files

[mysqld]
# SQL node options:
NodeId=5
HostName=10.0.0.154         

[mysqld]
# SQL node options:
NodeId=6
HostName=10.0.0.137         

[mysqld]
# SQL node options:
NodeId=7
HostName=10.0.0.115         
</div></code></pre>
</li>
</ul>
<p><em><strong>SQL节点</strong></em></p>
<ul>
<li>
<p>执行命令<code>groupadd mysql</code> <code>useradd -g mysql -s /bin/false mysql</code>创建Mysql用户及用户组</p>
</li>
<li>
<p>执行命令<code>chown -R root . &amp;&amp; chown -R mysql data &amp;&amp; chgrp -R mysql .</code>添加必要权限</p>
</li>
<li>
<p>执行命令<code>cp support-files/mysql.server /etc/rc.d/init.d/ &amp;&amp; chmod +x /etc/rc.d/init.d/mysql.server &amp;&amp; chkconfig --add mysql.server添加</code>mysql服务自启动</p>
</li>
<li>
<p>编辑<code>/etc/my.cnf</code>配置文件，添加SQL配置</p>
<pre class="hljs"><code><div>mysqld]
# Options for mysqld process:
ndbcluster                      # run NDB storage engine

[mysql_cluster]
# Options for NDB Cluster processes:
ndb-connectstring=vm1  # location of management server
</div></code></pre>
</li>
<li>
<p>执行命令<code>mysqld --initialize</code> <code>sudo systemctl mysql start</code>启动mysql服务</p>
</li>
</ul>
<p><em><strong>Data节点</strong></em></p>
<ul>
<li>
<p>执行命令<code>cp bin/ndbd /usr/local/bin/ndbd &amp;&amp; cp bin/ndbmtd /usr/local/bin/ndbmtd</code>拷贝可执行文件到PATH目录下</p>
</li>
<li>
<p>执行命令<code>cd /usr/local/bin &amp;&amp; chmod +x ndb*</code>添加可执行权限</p>
</li>
<li>
<p>编辑<code>/etc/my.cnf</code>配置文件，添加SQL配置</p>
<pre class="hljs"><code><div>mysqld]
# Options for mysqld process:
ndbcluster                      # run NDB storage engine

[mysql_cluster]
# Options for NDB Cluster processes:
ndb-connectstring=vm1  # location of management server
</div></code></pre>
</li>
</ul>
<h5 id="%E5%90%AF%E5%8A%A8mysql-cluster"><em>启动Mysql Cluster</em></h5>
<ul>
<li>
<p>进入Management节点，执行命令<code>ndb_mgmd -f /var/lib/mysql-cluster/config.ini</code>启动管理节点</p>
</li>
<li>
<p>进入Data节点，执行命令<code>ndbd</code>启动数据节点</p>
</li>
<li>
<p>进入Management节点，执行命令<code>ndb_mgm</code>之后<code>show</code>可以看到已经成功启动mysql集群</p>
<p><img src="./ds-imgs/mysql-cluster.png" alt=""></p>
</li>
</ul>
<h5 id="nginx%E7%BD%91%E5%85%B3%E5%8F%8A%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1">Nginx网关及负载均衡</h5>
<ul>
<li>
<p>执行命令<code>sudo yum -y install nginx</code>安装Nginx</p>
</li>
<li>
<p>编辑<code>/etc/nginx/nginx.conf</code>文件配置Web服务节点</p>
<pre class="hljs"><code><div>upstream serviceservers{
	server 10.0.0.154:8080;
	server 10.0.0.137:8080;
	server 10.0.0.115:8080;	
}

server {
    listen        30438;
    server_name  localhost;
    root         /usr/share/nginx/html;

    # Load configuration files for the default server block.
    include /etc/nginx/default.d/*.conf;

    location / {
    	proxy_pass http://serviceservers;
    }

    error_page 404 /404.html;
    	location = /40x.html {
    }

    error_page 500 502 503 504 /50x.html;
    	location = /50x.html {
    }
}

</div></code></pre>
</li>
</ul>

</body>
</html>
